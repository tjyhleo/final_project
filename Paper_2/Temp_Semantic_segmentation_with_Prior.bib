
@article{arth_instant_2015,
	title = {Instant {Outdoor} {Localization} and {SLAM} {Initialization} from 2.{5D} {Maps}},
	volume = {21},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2015.2459772},
	abstract = {We present a method for large-scale geo-localization and global tracking of mobile devices in urban outdoor environments. In contrast to existing methods, we instantaneously initialize and globally register a SLAM map by localizing the first keyframe with respect to widely available untextured 2.5D maps. Given a single image frame and a coarse sensor pose prior, our localization method estimates the absolute camera orientation from straight line segments and the translation by aligning the city map model with a semantic segmentation of the image. We use the resulting 6DOF pose, together with information inferred from the city map model, to reliably initialize and extend a 3D SLAM map in a global coordinate system, applying a model-supported SLAM mapping approach. We show the robustness and accuracy of our localization approach on a challenging dataset, and demonstrate unconstrained global SLAM mapping and tracking of arbitrary camera motion on several sequences.},
	number = {11},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Arth, Clemens and Pirchheim, Christian and Ventura, Jonathan and Schmalstieg, Dieter and Lepetit, Vincent},
	month = nov,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {2D map, Buildings, Cameras, geo-localization, image registration, Image segmentation, kim2018, Mobile handsets, Outdoor AR, Prior Map, Simultaneous localization and mapping, SLAM, Solid modeling, Three-dimensional displays},
	pages = {1309--1318},
	file = {IEEE Xplore Abstract Record:/home/ziwen/Zotero/storage/T324RWRS/7164332.html:text/html;IEEE Xplore Full Text PDF:/home/ziwen/Zotero/storage/6FEDFF7H/Arth et al. - 2015 - Instant Outdoor Localization and SLAM Initializati.pdf:application/pdf},
}

@inproceedings{hirzer_efficient_2017,
	address = {London, UK},
	title = {Efficient {3D} {Tracking} in {Urban} {Environments} with {Semantic} {Segmentation}},
	isbn = {978-1-901725-60-5},
	url = {http://www.bmva.org/bmvc/2017/papers/paper143/index.html},
	doi = {10.5244/C.31.143},
	abstract = {In this paper, we present a new 3D tracking approach for self-localization in urban environments. In particular, we build on existing tracking approaches (i.e., visual odometry tracking and SLAM), additionally using the information provided by 2.5D maps of the environment. Since this combination is not straightforward, we adopt ideas from semantic segmentation to ﬁnd a better alignment between the pose estimated by the tracker and the 2.5D model. Speciﬁcally, we show that introducing edges as semantic classes is highly beneﬁcial for our task. In this way, we can reduce tracker inaccuracies and prevent drifting, thus increasing the tracker’s stability. We evaluate our approach for two different challenging scenarios, also showing that it is generally applicable in different application domains and that we are not limited to a speciﬁc tracking method.},
	language = {en},
	urldate = {2022-05-10},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2017},
	publisher = {British Machine Vision Association},
	author = {Hirzer, Martin and Roth, Peter and Lepetit, Vincent},
	year = {2017},
	keywords = {AR},
	pages = {143},
	file = {Hirzer et al. - 2017 - Efficient 3D Tracking in Urban Environments with S.pdf:/home/ziwen/Zotero/storage/G624L9NC/Hirzer et al. - 2017 - Efficient 3D Tracking in Urban Environments with S.pdf:application/pdf},
}

@inproceedings{armagan_semantic_2017,
	title = {Semantic segmentation for {3D} localization in urban environments},
	doi = {10.1109/JURSE.2017.7924573},
	abstract = {We show how to use simple 2.5D maps of buildings and recent advances in image segmentation and machine learning to geo-localize an input image of an urban scene: We first extract the façades of the buildings and their edges from the image, and then look for the orientation and location that align a 3D rendering of the map with these segments. We discuss how to use a 3D tracking system to acquire the data required for training the segmentation method, the segmentation itself, and how we use the segmentations to evaluate the quality of the alignment.},
	booktitle = {2017 {Joint} {Urban} {Remote} {Sensing} {Event} ({JURSE})},
	author = {Armagan, Anil and Hirzer, Martin and Lepetit, Vincent},
	month = mar,
	year = {2017},
	keywords = {Buildings, Cameras, Image edge detection, Image segmentation, Semantics, Three-dimensional displays, Two dimensional displays},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/ziwen/Zotero/storage/PFSIPWWV/7924573.html:text/html;IEEE Xplore Full Text PDF:/home/ziwen/Zotero/storage/JY8AWTHL/Armagan et al. - 2017 - Semantic segmentation for 3D localization in urban.pdf:application/pdf},
}

@misc{pirchheim_zero-baseline_2015,
	title = {Zero-baseline 3d map initialization},
	publisher = {Google Patents},
	author = {Pirchheim, Christian and Ventura, Jonathan and Schmalstieg, Dieter and Arth, Clemens and Lepetit, Vincent},
	month = dec,
	year = {2015},
	annote = {US Patent App. 14/743,990},
	file = {US20150371440A1.pdf:/home/ziwen/Zotero/storage/4SAMBXG3/US20150371440A1.pdf:application/pdf},
}

@patent{hirzer_pose_2020,
	title = {Pose determination with semantic segmentation},
	url = {https://patents.google.com/patent/US10546387B2/en},
	nationality = {US},
	language = {en},
	assignee = {Qualcomm Inc},
	number = {US10546387B2},
	urldate = {2022-05-10},
	author = {Hirzer, Martin and Roth, Peter Michael and Arth, Clemens and Lepetit, Vincent},
	month = jan,
	year = {2020},
	keywords = {code, determining, image, pose, regions},
	file = {Full Text PDF:/home/ziwen/Zotero/storage/LATUIQDH/Hirzer et al. - 2020 - Pose determination with semantic segmentation.pdf:application/pdf},
}

@inproceedings{armagan_accurate_2017,
	address = {London, UK},
	title = {Accurate {Camera} {Registration} in {Urban} {Environments} {Using} {High}-{Level} {Feature} {Matching}},
	isbn = {978-1-901725-60-5},
	url = {http://www.bmva.org/bmvc/2017/papers/paper009/index.html},
	doi = {10.5244/C.31.9},
	abstract = {We propose a method for accurate camera pose estimation in urban environments from single images and 2D maps made of the surrounding buildings’ outlines. Our approach bridges the gap between learning-based approaches and geometric approaches: We use recent semantic segmentation techniques for extracting the buildings’ edges and the façades’ normals in the images and minimal solvers [14] to compute the camera pose accurately and robustly. We propose two such minimal solvers: one based on three correspondences of buildings’ corners from the image and the 2D map and another one based on two corner correspondences plus one façade correspondence. We show on a challenging dataset that, compared to recent state-of-the-art [1], this approach is both, faster and more accurate.},
	language = {en},
	urldate = {2022-05-10},
	booktitle = {Procedings of the {British} {Machine} {Vision} {Conference} 2017},
	publisher = {British Machine Vision Association},
	author = {Armagan, Anil and Hirzer, Martin and Roth, Peter and Lepetit, Vincent},
	year = {2017},
	pages = {9},
	file = {Armagan et al. - 2017 - Accurate Camera Registration in Urban Environments.pdf:/home/ziwen/Zotero/storage/UGTBPR3F/Armagan et al. - 2017 - Accurate Camera Registration in Urban Environments.pdf:application/pdf},
}

@inproceedings{armagan_learning_2017,
	title = {Learning to {Align} {Semantic} {Segmentation} and 2.{5D} {Maps} for {Geolocalization}},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Armagan_Learning_to_Align_CVPR_2017_paper.html},
	urldate = {2022-05-10},
	author = {Armagan, Anil and Hirzer, Martin and Roth, Peter M. and Lepetit, Vincent},
	year = {2017},
	pages = {3425--3432},
	file = {Full Text PDF:/home/ziwen/Zotero/storage/PMNP44BX/Armagan et al. - 2017 - Learning to Align Semantic Segmentation and 2.5D M.pdf:application/pdf;Snapshot:/home/ziwen/Zotero/storage/CC2NWB3C/Armagan_Learning_to_Align_CVPR_2017_paper.html:text/html},
}

@article{armagan_3d_nodate,
	title = {{3D} {Localization} in {Urban} {Environments} from {Single} {Images}},
	abstract = {In this paper, we tackle the problem of geolocalization in urban environments overcoming the limitations in terms of accuracy of sensors like GPS, compass and accelerometer. For that purpose, we adopt recent ﬁndings in image segmentation and machine learning and combine them with the valuable information given by 2.5D maps of buildings. In particular, we ﬁrst extract the fac¸ades of buildings and their edges and use this information to estimate the orientation and location that best align an input image to a 3D rendering of the given 2.5D map. As this step builds on a learned semantic segmentation procedure, rich training data is required. Thus, we also discuss how the required training data can be efﬁciently generated via a 3D tracking system.},
	language = {en},
	author = {Armagan, Anil and Hirzer, Martin and Roth, Peter M and Lepetit, Vincent},
	pages = {2},
	file = {Armagan et al. - 3D Localization in Urban Environments from Single .pdf:/home/ziwen/Zotero/storage/CXWTBKLG/Armagan et al. - 3D Localization in Urban Environments from Single .pdf:application/pdf},
}
